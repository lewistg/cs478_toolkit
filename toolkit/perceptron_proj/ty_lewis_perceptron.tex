\documentclass[12pt,letterpaper]{article}
\usepackage[latin1]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{amssymb}
\usepackage{placeins}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage[left=1.0in,top=1.0in,right=1.0in,bottom=1.0in]{geometry}
\usepackage{titling}
\setlength{\droptitle}{-4cm}
\renewcommand{\arraystretch}{1.1}
\usepackage{setspace}
\singlespacing

\title{Perceptron Project}
\author{Ty Lewis}
\begin{document} 
\maketitle
\vspace{-10pt}
\section*{Introduction}
The ``perceptron" is a simple machine learning algorithm capable of classifying... In this report we experiment with perceptron algorithm. This is done by, first, examining how well it labels linearly separable data versus data that is not linearly separable. Second, the perceptron is tested on 

\section*{Sensitivity to linear separability}

Sensitivity to linear separability was tested using training instances of two features $x \in [-1, 1]$ and $y \in [-1, 1]$. These $x$ and $y$ pairs were labeled either \emph{red} or \emph{blue}. One training set contained 4 red instances that were linearly separable from 4 blue instances. Another training set contained 4 red instances that were not linearly separable from the 4 blue instances. The perceptron trained on each set, stopping when 5 epochs had past without more than a 1 percent change in accuracy was observed between epochs.

\begin{wrapfigure}{r}{0.6\textwidth}
\vspace{-20pt}
\centering
\includegraphics[width=0.58\textwidth]{learning_rate_vs_epochs.eps} 
\vspace{-10pt}
\caption{Learning rate vs. epochs}
\vspace{-20pt}
\end{wrapfigure}

In one set of experiments, the effect of the learning rate on the amount of epochs it took to train was measured. The perceptron was trained using learning rates varying from $0.2$ to $2$. For each learning rate, 5 trials were run and the average number of epochs it took to finish training was measured. The graph in Figure 1 summarizes the results of this experiment.

\subsection*{Discussion of results}

A few features of this graph stand out. Note that for the linearly separable data, the number of epochs it took to train was relatively small. Conversely, it took much longer to train on the non-linearly separable data. It also appears that there is a high amount of variance in the non-linearly separable data. Indeed, for some learning rate experiments, the amount of epochs it took to train varied from as low as 9 all the way up to 80 or from 13 to 124. This was not the case for the linearly separable data. Overall, it doesn't appear that the number of epochs is very affected by this range of learning rates.


To see the For a learning rate of $0.1$, the following results were obtained.

\begin{center}
\begin{figure}[H]
	\begin{subfigure}[h]{0.5\textwidth}
		\includegraphics[scale=0.40]{linsep.eps} 
	\end{subfigure}
	\begin{subfigure}[h]{0.5\textwidth}
		\includegraphics[scale=0.40]{nonlinsep.eps} 
	\end{subfigure}
\caption{Results of perceptron and linearly separable and non-linearly separable data.}
\end{figure}
\end{center}

\section*{Voting task}

In this learning task, the perceptron seeks to identify Democrats and Republicans based on their stance on various issues. The table to the belows summarizes the performance of the perceptron for five trials. Note that in each trial the data was randomly split 70\% training and 30\% for testing.

%\begin{wrapfigure}{r}{0.6\textwidth}
\begin{figure}[H]
\centering
\begin{tabular}{cccc}
\toprule
Trial	&	Training set accuracy	&	Test set accuracy 	&	Epochs to train\\
\hline
1	&	96.9	&	95.7	&	37\\
2	&	94.7	&	95.7	&	46\\
3	&	97.5	&	94.9	&	19\\
4	&	97.8	&	94.2	&	86\\
5	&	97.8	&	90.6	&	10\\
\hline
Average	&	96.94	&	94.22	&	39.6\\
\bottomrule
\end{tabular}
\caption{Accuracy of perceptron trained and tested for voting task}
\end{figure}
%\end{wrapfigure}

Below is a graph depicting how the average error rate for the five trials changed after each epoch. Notice that after just a few epochs, the average error rate is already very low. The graph is also very sporadic. This may be due to the fact that trial 4 took much longer to train on than the others, essentially the average error rate consists of only trial 4's data beyond the $46$th epoch. Despite the sporadic data behavior, it is somewhat discernible that there is a general downward trend as the epoch continue.

\bigskip

%\begin{center}
%\begin{figure}[H]
\begin{wrapfigure}{r}{0.6\textwidth}
\centering
\includegraphics[width=0.55\textwidth]{error.pdf} 
\caption{Learning rate vs. epochs}
\vspace{-30pt}
\end{wrapfigure}
%\end{figure}
%\end{center}

For each trial, the final weights were extracted from the perceptron's model. The average of these weights is shown in the table below. Note that $w_i$ refers to the $i$th feature in the attributes section of the \emph{voting.arff} file (excluding the label feature). The last weight, $w_{16}$ is the bias weight.

\subsection*{Discussion of model}

The perceptron outputs a 0 if the feature pattern indicates a Democrat and a 1 for Republican. In other words the net-value is negative for Democrats and positive for Republicans. Notice that the largest negative weights are $w_3, w_4$, and $w_9$ which respectively refer to ``physician-fee-freeze", ``el-salvador-aide", and ``immigration." We can take these large negative weights to mean that these are the most significant indicators of a Democrat. Alternatively, $w_{10}, w_2$, and $w_8$ are the largest positive weights. They correspond to ``synfuels-corporation-cutback", ``adoption-of-the-budget-resolution", and ``mx-missile" respectively. Similarly, these are the most significant predictors of a Republican. 

\begin{figure}[h]
\centering

\begin{tabular}{c|c||c|c||c|c||c|c||c|c}
\toprule
\multicolumn{10}{c}{Voting Task Model} \\
\hline
$w_{0}$	&	0.16	&	$w_{4}$	&	-0.66	&	$w_{8}$	&	0.76	&	$w_{12}$	&	-0.1	&	$w_{16}$	&	1.42\\
$w_{1}$	&	0.3	&	$w_{5}$	&	0.14	&	$w_{9}$	&	-0.54	&	$w_{13}$	&	0.12	&		&	\\
$w_{2}$	&	0.76	&	$w_{6}$	&	-0.4	&	$w_{10}$	&	1.04	&	$w_{14}$	&	0.48	&		&	\\
$w_{3}$	&	-1.88	&	$w_{7}$	&	-0.8	&	$w_{11}$	&	-0.02	&	$w_{15}$	&	-0.26	&		&	\\
\bottomrule
\end{tabular}
\caption{Average weights for perceptron model after training on voting task.}
\end{figure}

\section*{Iris task}

\textbf{Note:} For the iris learning task, training is stopped once 100 epochs have passed without a significant improvement in the best model found so far. (Using the stopping criteria from previous experiments often never halted training; the training set accuracy simply thrashed from as low as 60\% to as high as 90\%, never converging.)

Below is the table showing accuracy of the model for the training set and the test set.

\begin{center}
\begin{tabular}{cccc}
\toprule
Trial	&	Training set accuracy	&	Test set accuracy 	&	Epochs to train\\
\hline
1	&	95.2	&	95.6	&	121\\
2	&	95.2	&	88.2	&	110\\
3	&	95.2	&	93.3	&	164\\
4	&	96.2	&	91.1	&	191\\
5	&	95.2	&	97.8	&	106\\
Average	&	95.4	&	93.2	&	138.4\\
\bottomrule
\end{tabular}
\end{center}

For this data set there were three possible output classes that could be assigned to each instance, namely iris-setosa, iris-versicolor, and iris-virginica. In order to deal with this, a perceptron was created for flower type and trained to identify only that type. The table below shows the average weights for each perceptron. Again, the $i$th weight corresponds to the $i$th feature in the \emph{iris.arff} file (excluding the label attribute) and $w_5$ is the bias weight.

\begin{center}
\begin{tabular}{lccccc}
\toprule
\multicolumn{6}{c}{Iris Task Models} \\
\hline
Flower Modeled	&	$w_0$	&	$w_1$	&	$w_2$	&	$w_4$	&	$w_5$\\
\hline
Iris-setosa	&	0.158	&	0.514	&	-0.8	&	-0.386	&	0.1\\
Iris-versicolor	&	1.114	&	-3.714	&	2.006	&	-4.922	&	3.18\\
Iris-virginica	&	-2.426	&	-2.716	&	3.974	&	3.816	&	-1.58\\
\bottomrule
\end{tabular}
\end{center}

\subsection*{Discussion of model}

\section*{My own experiment}

For my own experiment, I experimented with separating points using a degree-3 polynomial. Similar to the first part of this lab, I created seven $x$ and $y$ coordinate pairs lying on either side of the polynomial $y = x^3 - 3x^2 - x + 5$. I then created an \emph{arff} file containing the attributes $x$, $y$, $x^3$, $x^2$, and color. The seven points that came from the left of the curve were labeled ``red" and the ones to the right of the curve were labeled ``blue."

The table below shows the resulting weights after five trials running in the training evaluation method. Each set of weights resulted in 100\% accuracy.

\begin{center}
\begin{tabular}{cccccc}
\toprule
Trial & $w_0$ & $w_1$ & $w_2$ & $w_3$ & $w_4$ \\
\hline
1 & 4.38409	&	2.90633	&	-3.84122	&	9.51148	&	-10.9\\
2 & 5.34182	&	3.06776	&	-3.93253	&	9.24562	&	-11\\
3 & 5.17142	&	3.58455	&	-4.57759	&	11.1096	&	-12.6\\
4 & 5.91608	&	3.64871	&	-4.92576	&	11.6396	&	-12.3\\
5 & 6.66132	&	4.23084	&	-5.01142	&	11.8543	&	-15.3\\
\bottomrule
\end{tabular}
\end{center}


The graph below shows a plot of the points along with each of the parabolas defined by the weights in table above. 

\end{document}